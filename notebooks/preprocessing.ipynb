{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39afe785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "import requests\n",
    "import pandas as pd \n",
    "from typing import List, Dict \n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import time \n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddbc8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path(\"../data/\")\n",
    "FINETUNING_DIR = OUTPUT_DIR / \"finetuning\"\n",
    "RAG_DIR = OUTPUT_DIR / \"rag\"\n",
    "\n",
    "FINETUNING_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RAG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88fe0c",
   "metadata": {},
   "source": [
    "### Dataset For Finetuning : medication QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82a87576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mediqationqa(file_path):\n",
    "\tdf = pd.read_excel(file_path)\n",
    "\t# convert to finetuning format\n",
    "\tfinetuning_data = []\n",
    "\tfor _, row in df.iterrows():\n",
    "\t\t# clean and format \n",
    "\t\tquestion = str(row.ge('Question', '')).strip()\n",
    "\t\tanswer = str(row.get('Answer', '')).strip()\n",
    "\t\tfocus = str(row.get('Focus (Drug)', '')).strip()\n",
    "\t\t\n",
    "\t\tif question and answer and question != 'nan' and answer != 'nan':\n",
    "\t\t\tfinetuning_data.append({\n",
    "\t\t\t\t\t\t\"instruction\" : question,\n",
    "\t\t\t\t\t\t\"output\": answer,\n",
    "\t\t\t\t\t\t\"focus_drug\": focus,\n",
    "\t\t\t\t\t\t\"source\": \"MedicationQA\"\n",
    "\t\t\t})\n",
    "\t\n",
    "\treturn finetuning_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c578b44",
   "metadata": {},
   "source": [
    "### Dataset for Knowledge Base for simple RAG using FAISS : DailyMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77eaf3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_dailymed_drug_info(drug_name: str, verbose=True):\n",
    "    \"\"\"\n",
    "    Final version: Fetch DailyMed XML using API v1 with correct drug filtering.\n",
    "    - Step 1: Search SPLs by exact drug name (v1)\n",
    "    - Step 2: Select latest SPL version\n",
    "    - Step 3: Download SPL XML via v2 endpoint\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------\n",
    "    # STEP 1 ‚Äî QUERY API v1\n",
    "    # -------------------------\n",
    "    url = f\"https://dailymed.nlm.nih.gov/dailymed/services/v1/drugname/{drug_name}/human/spls.json\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"‚ùå Error searching SPL for {drug_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "    rows = data.get(\"DATA\", [])\n",
    "    if not rows:\n",
    "        if verbose:\n",
    "            print(f\"‚ö† No SPL entries found for drug '{drug_name}'\")\n",
    "        return None\n",
    "\n",
    "    # -------------------------\n",
    "    # STEP 2 ‚Äî Pick latest SPL\n",
    "    # -------------------------\n",
    "    def parse_date(date_str):\n",
    "        try:\n",
    "            return datetime.strptime(date_str, \"%B %d, %Y\")\n",
    "        except:\n",
    "            return datetime.min\n",
    "\n",
    "    # rows format:\n",
    "    # [ SETID, TITLE, SPL_VERSION, PUBLISHED_DATE ]\n",
    "    latest_row = max(rows, key=lambda r: parse_date(r[3]))\n",
    "\n",
    "    setid = latest_row[0]\n",
    "    title = latest_row[1]\n",
    "    published = latest_row[3]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"‚úÖ Found SPL for {drug_name}\")\n",
    "        print(f\"   Title     : {title}\")\n",
    "        print(f\"   SETID     : {setid}\")\n",
    "        print(f\"   Published : {published}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # STEP 3 ‚Äî DOWNLOAD XML\n",
    "    # -------------------------\n",
    "    xml_url = f\"https://dailymed.nlm.nih.gov/dailymed/services/v2/spls/{setid}.xml\"\n",
    "\n",
    "    try:\n",
    "        xml_resp = requests.get(xml_url, timeout=15)\n",
    "        xml_resp.raise_for_status()\n",
    "        xml_dict = xmltodict.parse(xml_resp.content)\n",
    "        if verbose:\n",
    "            print(f\"üì¶ Successfully fetched XML for {drug_name}\")\n",
    "        return xml_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"‚ùå Failed to fetch XML for SETID {setid}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0eea91df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found SPL for Ibuprofen\n",
      "   Title     : IBUPROFEN TABLET [APHENA PHARMA SOLUTIONS - TENNESSEE, LLC ]\n",
      "   SETID     : 4522cb9e-4999-c455-e063-6294a90a294f\n",
      "   Published : December 05, 2025\n",
      "üì¶ Successfully fetched XML for Ibuprofen\n"
     ]
    }
   ],
   "source": [
    "data = fetch_dailymed_drug_info(\"Ibuprofen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0bea97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to clean html tag from text \n",
    "import re\n",
    "\n",
    "def strip_tags(xml_string):\n",
    "\t# hapus semua tag <...>\n",
    "\ttext = re.sub(r\"<[^>]+>\", \" \", xml_string)\n",
    "\t# normalisasi whitespace\n",
    "\ttext = re.sub(r\"\\s+\", \" \", text)\n",
    "\treturn text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d8897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drug_sections(xml_dict, drug_name):\n",
    "\tif not xml_dict:\n",
    "\t\treturn []\n",
    "\t\n",
    "\tsection_of_interest = {\n",
    "\t\t\t'dosage' : ['DOSAGE', 'DOSAGE AND ADMINISTRATION'], \n",
    "\t\t\t'contraindications': ['CONTRAINDICATIONS SECTION', 'CONTRAINDICATIONS'],\n",
    "\t\t\t'side_effects': ['ADVERSE REACTIONS', 'SIDE EFFECTS'],\n",
    "\t\t\t'mechanism': ['MECHANISM OF ACTION', 'CLINICAL PHARMACOLOGY'],\n",
    "\t\t\t'warnings': ['WARNINGS', 'WARNINGS AND PRECAUTIONS'], \n",
    "\t\t\t'indications': ['INDICATIONS', 'INDICATIONS AND USAGE'], \n",
    "\t\t\t'interactions': ['DRUG INTERACTIONS'],\n",
    "\t\t\t'overdosage': ['OVERDOSAGE']\n",
    "\t}\n",
    "\n",
    "\trag_chunks = []\n",
    "\n",
    "\ttry:\n",
    "\t\tcomponents = (\n",
    "\t\t\txml_dict.get(\"document\", {})\n",
    "\t\t\t\t\t\t\t.get(\"component\", {})\n",
    "\t\t\t\t\t\t\t.get(\"structuredBody\", {})\n",
    "\t\t\t\t\t\t\t.get(\"component\", [])\n",
    "\t\t)\n",
    "\n",
    "\t\t# fallback if structureBody is not present\n",
    "\t\t# if not components:\n",
    "\t\t# \tprint(\"Falling back to direct components\")\n",
    "\t\t# \tcomponents = xml_dict.get(\"document\", {}).get(\"component\", [])\n",
    "\n",
    "\t\t# components should be a list \n",
    "\t\tif isinstance(components, dict):\n",
    "\t\t\tcomponents = [components]\n",
    "\t\t\n",
    "\t\tfor comp in components:\n",
    "\t\t\tsection = comp.get(\"section\", {})\n",
    "\t\t\tif not section:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t# extract section title \n",
    "\t\t\tcode = section.get(\"code\", {})\n",
    "\t\t\ttitle = code.get(\"@displayName\", \"\").upper()\n",
    "\n",
    "\t\t\t# extract raw text (it can be list or dict)\n",
    "\t\t\ttext = section.get(\"text\", \"\")\n",
    "\t\t\tif isinstance(text, dict):\n",
    "\t\t\t\t# convert HTML-ish XML content to string\n",
    "\t\t\t\ttext = xmltodict.unparse({\"text\": text}, pretty=False)\n",
    "\n",
    "\t\t\tif isinstance(text, list):\n",
    "\t\t\t\ttext = \"\\n\".join(str(t) for t in text)\n",
    "\t\t\t\n",
    "\t\t\ttext = str(text).strip()\n",
    "\n",
    "\t\t\t# clean tags \n",
    "\t\t\ttext = strip_tags(text)\n",
    "\n",
    "\t\t\t# match section with interest list\n",
    "\t\t\tfor category, keywords in section_of_interest.items():\n",
    "\t\t\t\tif any(k in title for k in keywords):\n",
    "\t\t\t\t\tif len(text) > 50:\n",
    "\t\t\t\t\t\trag_chunks.append({\n",
    "\t\t\t\t\t\t\t\"drug_name\": drug_name,\n",
    "\t\t\t\t\t\t\t\"category\": category,\n",
    "\t\t\t\t\t\t\t\"section_title\": title,\n",
    "\t\t\t\t\t\t\t\"text\": text[:2000],  # limit to first 2000 chars\n",
    "\t\t\t\t\t\t\t\"source\": \"DailyMed\"\n",
    "\t\t\t\t\t\t})\n",
    "\t\t\t\t\tbreak # stop checking other categories once matched\n",
    "\t\t\t\n",
    "\t\treturn rag_chunks\n",
    "\t\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error extracting sections for {drug_name}: {e}\")\n",
    "\t\treturn []\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07ee8ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found SPL for Acetaminophen\n",
      "   Title     : EXTRA STRENGTH PAIN RELIEF (ACETAMINOPHEN) TABLET [GERI-CARE PHARMACEUTICAL CORP]\n",
      "   SETID     : 7570aaa2-3238-4cd3-b788-915caa970dba\n",
      "   Published : December 05, 2025\n",
      "üì¶ Successfully fetched XML for Acetaminophen\n",
      "3\n",
      "Acetaminophen\n",
      "indications\n",
      "INDICATIONS & USAGE SECTION\n",
      "temporarily relieves minor aches and pains temporarily reduces fever\n",
      "\n",
      "Acetaminophen\n",
      "warnings\n",
      "WARNINGS SECTION\n",
      "Liver warning: This product contains acetaminophen. Severe liver damage may occur if you take Allergy alert: acetaminophen may cause severe skin reactions. Symptoms may include: ‚Ä¢ skin reddening ‚Ä¢ blisters ‚Ä¢ rash If a skin reaction occurs, stop use and seek medical help right away. Do not use Ask a doctor before use if you have liver disease. Ask a doctor or pharmacist before use if you are taking the blood thinning drug warfarin. Stop use and ask a doctor if These could be signs of a serious condition. If pregnant or breast-feeding, ask a health professional before use. more than 8 tablets (4,000 mg of acetaminophen) in 24 hours with other drugs containing acetaminophen 3 or more alcoholic drinks every day while using this product with any other drug containing acetaminophen (prescription or nonprescription). If you are not sure whether a drug contains acetaminophen, ask a doctor or pharmacist. if you are allergic to acetaminophen or any of the inactive ingredients in this product pain gets worse or lasts more than 10 days fever gets worse or lasts more than 3 days new symptom occur redness or swelling is present\n",
      "\n",
      "Acetaminophen\n",
      "dosage\n",
      "DOSAGE & ADMINISTRATION SECTION\n",
      "do not take more than directed adults and children 12 years and over: Take 2 tablets every 6 hours, as needed; not more than 6 tablets in 24 hours. Do not take for more than 10 days unless directed by a doctor. children under 12 years: ask a doctor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xml_dict = fetch_dailymed_drug_info(\"Acetaminophen\")\n",
    "chunks = extract_drug_sections(xml_dict, \"Acetaminophen\")\n",
    "\n",
    "print(len(chunks))\n",
    "for c in chunks:\n",
    "\tprint(c[\"drug_name\"])\n",
    "\tprint(c[\"category\"])\n",
    "\tprint(c[\"section_title\"])\n",
    "\tprint(c[\"text\"])\n",
    "\tprint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b11674ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DRUGS =[\n",
    "\t\"Aspirin\", \"Ibuprofen\", \"Acetaminophen\",\n",
    "\t\"Amoxicillin\", \"Azithromycin\", \"Ciprofloxacin\",\n",
    "\t\"Metformin\", \"Atorvastatin\", \"Lisinopril\",\n",
    "\t\"Omeprazole\", \"Levothyroxine\", \"Albuterol\",\n",
    "\t\"Gabapentin\", \"Sertraline\", \"Losartan\",\n",
    "\t\"Vitamin D\", \"Vitamin B12\", \"Vitamin C\"\n",
    "]\n",
    "\n",
    "\n",
    "def build_rag_knowledge_base():\n",
    "\tprint(\"Building RAG Knowledge Base from DailyMed...\")\n",
    "\n",
    "\tall_rag_chunks = []\n",
    "\tfor drug in TARGET_DRUGS:\n",
    "\t\ttime.sleep(1)  # to respect API rate limits\n",
    "\t\t# fetch xml data\n",
    "\t\txml_dict = fetch_dailymed_drug_info(drug)\n",
    "\n",
    "\t\tif not xml_dict:\n",
    "\t\t\tprint(f\"No dailymed data for {drug}\")\n",
    "\t\t\tcontinue \n",
    "\n",
    "\t\t# extract section \n",
    "\t\tchunks = extract_drug_sections(xml_dict, drug)\n",
    "\t\tprint(f\" ‚úì Extracted {len(chunks)} chunks\")\n",
    "\n",
    "\t\tall_rag_chunks.extend(chunks)\n",
    "\n",
    "\t\ttime.sleep(1)  # to respect API rate limits\n",
    "\n",
    "\tprint(f\"‚úì Total RAG chunks collected: {len(all_rag_chunks)}\")\n",
    "\treturn all_rag_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d562169",
   "metadata": {},
   "source": [
    "### Save finetuning dataset and rag dataset\n",
    "if the two cell below run more than once it will override curren json and jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8842e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_finetuning_data(qa_pairs : List[Dict]):\n",
    "\tprint(f\"Saving finetuning dataset... {len(qa_pairs)} pairs\")\n",
    "\n",
    "\t# split train test 90 : 10\n",
    "\tsplit_idx = int(len(qa_pairs) * 0.9)\n",
    "\ttrain_data = qa_pairs[:split_idx]\n",
    "\ttest_data = qa_pairs[split_idx:]\n",
    "\n",
    "\t# save as JSON \n",
    "\twith open(FINETUNING_DIR / \"train.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "\t\tjson.dump(train_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\twith open(FINETUNING_DIR / \"test.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "\t\tjson.dump(test_data, f, indent=2, ensure_ascii=False)\n",
    "\t\n",
    "\t# save as JSONL\n",
    "\twith open(FINETUNING_DIR / \"train.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "\t\tfor item in train_data:\n",
    "\t\t\tf.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\twith open(FINETUNING_DIR / \"test.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "\t\tfor item in test_data:\n",
    "\t\t\tf.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\t\n",
    "\tprint(f\"Train set: {len(train_data)} samples\")\n",
    "\tprint(f\"Test set: {len(test_data)} samples\")\n",
    "\tprint(f\"Data saved to {FINETUNING_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "401f841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rag_data(rag_chunks):\n",
    "\tprint(\"Saving RAG knowledge base...\")\n",
    "\t\n",
    "\t# save as JSON\n",
    "\twith open(RAG_DIR / \"knowledge_base.json\", 'w', encoding='utf-8') as f:\n",
    "\t\tjson.dump(rag_chunks, f, indent=2, ensure_ascii=False)\n",
    "\t\n",
    "\t# save as JSONL\n",
    "\twith open(RAG_DIR / \"knowledge_base.jsonl\", 'w', encoding='utf-8') as f:\n",
    "\t\tfor chunk in rag_chunks:\n",
    "\t\t\tf.write(json.dumps(chunk, ensure_ascii=False) + \"\\n\")\n",
    "\t\n",
    "\t# save statistic \n",
    "\tstats = {\n",
    "\t\t'total_chunks': len(rag_chunks),\n",
    "\t\t'chunks_per_drug': {},\n",
    "\t\t'chunks_per_category': {}\n",
    "\t}\n",
    "\n",
    "\tfor chunk in rag_chunks:\n",
    "\t\tdrug = chunk['drug_name']\n",
    "\t\tcategory = chunk['category']\n",
    "\t\tstats['chunks_per_drug'][drug] = stats['chunks_per_drug'].get(drug, 0) + 1\n",
    "\t\tstats['chunks_per_category'][category] = stats['chunks_per_category'].get(category, 0) + 1\n",
    "\t\n",
    "\twith open(RAG_DIR / \"stats.json\", 'w', encoding='utf-8') as f:\n",
    "\t\tjson.dump(stats, f, indent=2)\n",
    "\t\n",
    "\tprint(f\"Total chunks : {len(rag_chunks)}\")\n",
    "\tprint(f\"Saved to {RAG_DIR}\")\n",
    "\tfor drug, count in stats['chunks_per_drug'].items():\n",
    "\t\tprint(f\" - {drug}: {count} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c04b251",
   "metadata": {},
   "source": [
    "### Execute All Function Above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "598f2274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building RAG Knowledge Base from DailyMed...\n",
      "‚úÖ Found SPL for Aspirin\n",
      "   Title     : BAYER LOW DOSE (ASPIRIN) TABLET [BAYER HEALTHCARE LLC.]\n",
      "   SETID     : 075b103e-0bb4-4b7a-ac0e-5645bcbd0a07\n",
      "   Published : December 05, 2025\n",
      "üì¶ Successfully fetched XML for Aspirin\n",
      " ‚úì Extracted 2 chunks\n",
      "‚úÖ Found SPL for Ibuprofen\n",
      "   Title     : IBUPROFEN TABLET [APHENA PHARMA SOLUTIONS - TENNESSEE, LLC ]\n",
      "   SETID     : 4522cb9e-4999-c455-e063-6294a90a294f\n",
      "   Published : December 05, 2025\n",
      "üì¶ Successfully fetched XML for Ibuprofen\n",
      " ‚úì Extracted 6 chunks\n",
      "‚úÖ Found SPL for Acetaminophen\n",
      "   Title     : EXTRA STRENGTH PAIN RELIEF (ACETAMINOPHEN) TABLET [GERI-CARE PHARMACEUTICAL CORP]\n",
      "   SETID     : 7570aaa2-3238-4cd3-b788-915caa970dba\n",
      "   Published : December 05, 2025\n",
      "üì¶ Successfully fetched XML for Acetaminophen\n",
      " ‚úì Extracted 3 chunks\n",
      "‚úÖ Found SPL for Amoxicillin\n",
      "   Title     : AMOXICILLIN FOR SUSPENSION [NUCARE PHARMACEUTICALS, INC.]\n",
      "   SETID     : 4528f48d-5bda-b307-e063-6294a90a294c\n",
      "   Published : December 05, 2025\n",
      "üì¶ Successfully fetched XML for Amoxicillin\n",
      " ‚úì Extracted 5 chunks\n",
      "‚úÖ Found SPL for Azithromycin\n",
      "   Title     : AZITHROMYCIN TABLET, FILM COATED [BIONPHARMA INC.]\n",
      "   SETID     : 859bb02c-a4bc-46fa-9fc9-def1219b5dfb\n",
      "   Published : December 05, 2025\n",
      "üì¶ Successfully fetched XML for Azithromycin\n",
      " ‚úì Extracted 4 chunks\n",
      "‚úÖ Found SPL for Ciprofloxacin\n",
      "   Title     : CIPROFLOXACIN (CIPROFOLXACIN) TABLET [NUCARE PHARMACEUTICALS,INC.]\n",
      "   SETID     : 1b189dba-0493-c9b4-e063-6294a90a7d1e\n",
      "   Published : December 04, 2025\n",
      "üì¶ Successfully fetched XML for Ciprofloxacin\n",
      " ‚úì Extracted 5 chunks\n",
      "‚úÖ Found SPL for Metformin\n",
      "   Title     : METFORMIN (METFORMIN ER 500 MG) TABLET, EXTENDED RELEASE METFORMIN (METFORMIN ER 750 MG) TABLET, EXTENDED RELEASE [GRANULES PHARMACEUTICALS INC.]\n",
      "   SETID     : 6d6ee6f8-9650-ff4f-e053-2991aa0acf19\n",
      "   Published : December 05, 2025\n",
      "üì¶ Successfully fetched XML for Metformin\n",
      " ‚úì Extracted 6 chunks\n",
      "‚úÖ Found SPL for Atorvastatin\n",
      "   Title     : ATORVASTATIN CALCIUM (ATORVASTATIN) TABLET, FILM COATED [DIRECT RX]\n",
      "   SETID     : 7a3d0c78-f0a7-0706-e053-2991aa0ae9f7\n",
      "   Published : January 11, 2021\n",
      "üì¶ Successfully fetched XML for Atorvastatin\n",
      " ‚úì Extracted 9 chunks\n",
      "‚úÖ Found SPL for Lisinopril\n",
      "   Title     : LISINOPRIL TABLET [REMEDYREPACK INC.]\n",
      "   SETID     : 463308ef-16cb-41d8-8d29-6aae2c5a7b0f\n",
      "   Published : December 02, 2025\n",
      "üì¶ Successfully fetched XML for Lisinopril\n",
      " ‚úì Extracted 1 chunks\n",
      "‚úÖ Found SPL for Omeprazole\n",
      "   Title     : OMEPRAZOLE CAPSULE, DELAYED RELEASE [A-S MEDICATION SOLUTIONS]\n",
      "   SETID     : 17ccdbe0-19c1-498d-8e81-578be549b4e5\n",
      "   Published : December 04, 2025\n",
      "üì¶ Successfully fetched XML for Omeprazole\n",
      " ‚úì Extracted 5 chunks\n",
      "‚úÖ Found SPL for Levothyroxine\n",
      "   Title     : LEVOTHYROXINE LIQUID [DESERET BIOLOGICALS, INC.]\n",
      "   SETID     : 1a467f8b-2611-4936-af2b-098e4791d6ae\n",
      "   Published : December 14, 2023\n",
      "üì¶ Successfully fetched XML for Levothyroxine\n",
      " ‚úì Extracted 3 chunks\n",
      "‚úÖ Found SPL for Albuterol\n",
      "   Title     : ALBUTEROL TABLET [BRYANT RANCH PREPACK]\n",
      "   SETID     : 601a18ed-d66e-498f-a804-f1a3330827d4\n",
      "   Published : April 23, 2025\n",
      "üì¶ Successfully fetched XML for Albuterol\n",
      " ‚úì Extracted 7 chunks\n",
      "‚úÖ Found SPL for Gabapentin\n",
      "   Title     : GABAPENTIN CAPSULE [GRANULES PHARMACEUTICALS INC.]\n",
      "   SETID     : b20ee34a-7f2d-4d62-a161-898565f74547\n",
      "   Published : December 05, 2025\n",
      "üì¶ Successfully fetched XML for Gabapentin\n",
      " ‚úì Extracted 5 chunks\n",
      "‚úÖ Found SPL for Sertraline\n",
      "   Title     : SERTRALINE TABLET, FILM COATED [REMEDYREPACK INC.]\n",
      "   SETID     : 7efc1dd5-8671-4bed-9c16-ef6b9f36afc4\n",
      "   Published : October 06, 2025\n",
      "üì¶ Successfully fetched XML for Sertraline\n",
      " ‚úì Extracted 5 chunks\n",
      "‚úÖ Found SPL for Losartan\n",
      "   Title     : LOSARTAN POTASSIUM (LOSARTAN) TABLET [GRANULES PHARMACEUTICALS INC.]\n",
      "   SETID     : ca012edc-923d-4ada-a261-db82b71b3c4f\n",
      "   Published : December 05, 2025\n",
      "üì¶ Successfully fetched XML for Losartan\n",
      " ‚úì Extracted 3 chunks\n",
      "‚ùå Error searching SPL for Vitamin D: 404 Client Error: Not Found for url: https://dailymed.nlm.nih.gov/dailymed/services/v1/drugname/Vitamin%20D/human/spls.json\n",
      "No dailymed data for Vitamin D\n",
      "‚ùå Error searching SPL for Vitamin B12: 404 Client Error: Not Found for url: https://dailymed.nlm.nih.gov/dailymed/services/v1/drugname/Vitamin%20B12/human/spls.json\n",
      "No dailymed data for Vitamin B12\n",
      "‚ùå Error searching SPL for Vitamin C: 404 Client Error: Not Found for url: https://dailymed.nlm.nih.gov/dailymed/services/v1/drugname/Vitamin%20C/human/spls.json\n",
      "No dailymed data for Vitamin C\n",
      "‚úì Total RAG chunks collected: 69\n",
      "Saving finetuning dataset... 689 pairs\n",
      "Train set: 620 samples\n",
      "Test set: 69 samples\n",
      "Data saved to ..\\data\\finetuning\n",
      "Saving RAG knowledge base...\n",
      "Total chunks : 69\n",
      "Saved to ..\\data\\rag\n",
      " - Aspirin: 2 chunks\n",
      " - Ibuprofen: 6 chunks\n",
      " - Acetaminophen: 3 chunks\n",
      " - Amoxicillin: 5 chunks\n",
      " - Azithromycin: 4 chunks\n",
      " - Ciprofloxacin: 5 chunks\n",
      " - Metformin: 6 chunks\n",
      " - Atorvastatin: 9 chunks\n",
      " - Lisinopril: 1 chunks\n",
      " - Omeprazole: 5 chunks\n",
      " - Levothyroxine: 3 chunks\n",
      " - Albuterol: 7 chunks\n",
      " - Gabapentin: 5 chunks\n",
      " - Sertraline: 5 chunks\n",
      " - Losartan: 3 chunks\n",
      "Preprocessing completed.\n"
     ]
    }
   ],
   "source": [
    "# finetuning dataset\n",
    "all_qa_pairs = []\n",
    "mediqationqa_data = process_mediqationqa(\"../data/finetuning/MedInfo2019-QA-Medications.xlsx\")\n",
    "all_qa_pairs.extend(mediqationqa_data)\n",
    "\n",
    "# rag dataset\n",
    "rag_chunks = build_rag_knowledge_base()\n",
    "\n",
    "# save dataset \n",
    "if all_qa_pairs:\n",
    "  save_finetuning_data(all_qa_pairs)\n",
    "  \n",
    "if rag_chunks:\n",
    "  save_rag_data(rag_chunks)\n",
    "\n",
    "print(\"Preprocessing completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
